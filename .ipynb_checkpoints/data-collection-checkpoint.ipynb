{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Dog Toy Recommendation System \n",
    "### Data Collection \n",
    "In order to collect my data, I will use Selenium and ChromeDriver in order to scrape dog toy reviews from Chewy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources used throughout this pages:\n",
    "https://selenium-python.readthedocs.io/locating-elements.html#locating-hyperlinks-by-link-text\n",
    "https://www.scrapingbee.com/blog/selenium-python/\n",
    "https://www.scrapingbee.com/blog/practical-xpath-for-web-scraping/\n",
    "https://www.scrapingbee.com/blog/scraping-single-page-applications/\n",
    "https://stackoverflow.com/questions/11549647/getting-the-url-of-the-current-page-using-selenium-webdriver\n",
    "https://towardsdatascience.com/in-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319\n",
    "https://medium.com/ymedialabs-innovation/web-scraping-using-beautiful-soup-and-selenium-for-dynamic-page-2f8ad15efe25\n",
    "https://towardsdatascience.com/web-scraping-using-selenium-python-8a60f4cf40ab\n",
    "https://towardsdatascience.com/5-top-tips-for-data-scraping-using-selenium-d8b83804681c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in my selenium_practice.py file so far for scraping data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# imports \n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_title(page_source):\n",
    "    toy_list = []\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    \n",
    "    # Getting the toy's title \n",
    "    section = soup.find('section', id='right-column')\n",
    "    title = section.find('div', id='product-title').find('h1').get_text().strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_price(page_source):\n",
    "    # Getting the toy's price \n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    price = soup.find('div', id='pricing').find(\n",
    "        'ul', class_='product-pricing').find(\n",
    "        'li', class_='our-price').find(\n",
    "        'p', class_='price').find(\n",
    "        'span', class_='ga-eec__price').get_text().strip()\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_description(page_source):\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    try:\n",
    "        descriptions =  soup.find(\n",
    "            'div', class_='cw-tabs__body container').find(\n",
    "            'article', id='descriptions').find(\n",
    "            'section', class_='descriptions__content cw-tabs__content--left').find_all(\n",
    "            'p')\n",
    "        text_list = []\n",
    "        for description in descriptions:\n",
    "            text = description.get_text()\n",
    "            text_list.append(text)\n",
    "    \n",
    "    except:\n",
    "        description =  soup.find(\n",
    "                'div', class_='cw-tabs__body container').find(\n",
    "                'article', id='descriptions').find(\n",
    "                'section', class_='descriptions__content cw-tabs__content--left').find(\n",
    "                'p')\n",
    "        text_list = []\n",
    "        text = description.get_text()\n",
    "        text_list.append(text)\n",
    "    \n",
    "    else: \n",
    "        pass\n",
    "    return text_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_toy_description(page_source):\n",
    "#     soup = BeautifulSoup(page_source, 'lxml')\n",
    "#     descriptions =  soup.find(\n",
    "#             'div', class_='cw-tabs__body container').find(\n",
    "#             'article', id='descriptions').find(\n",
    "#             'section', class_='descriptions__content cw-tabs__content--left').find_all(\n",
    "#             'p')\n",
    "#     text_list = []\n",
    "#     for description in descriptions:\n",
    "#         text = description.get_text()\n",
    "#         text_list.append(text)\n",
    "#     return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_keybenefits(page_source):\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    ul = soup.find(\n",
    "        'div', class_='cw-tabs__body container').find(\n",
    "        'article', id='descriptions').find(\n",
    "        'section', class_='descriptions__content cw-tabs__content--left').find(\n",
    "        'ul')\n",
    "    lis = ul.find_all('li')\n",
    "    text_list = []\n",
    "    for li in lis:\n",
    "        text = li.get_text()\n",
    "        text_list.append(text)\n",
    "\n",
    "#             If you want each key benefit to be in its own list run this instead \n",
    "#             text_item = []\n",
    "#             text = li.get_text()\n",
    "#             text_item.append(text)\n",
    "#             text_list.append(text_item)\n",
    "\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_rating(page_source):\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    picture = soup.find(\n",
    "        'div', class_='product-header-extras').find(\n",
    "        'div', class_='ugc ugc-head').find(\n",
    "        'picture')\n",
    "    img = picture.find('img') # How do I access the img and then the stuff inside the img? \n",
    "    rating = img['src']\n",
    "    return rating[-7:-4] # Grabbing the number itself from the 'src' attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_reviews(page_source): \n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    reviews = soup.find_all('span', class_='ugc-list__review__display')\n",
    "#     print(len(reviews))\n",
    "#     print(reviews[0].get_text())\n",
    "    text_list = []\n",
    "    for review in reviews:\n",
    "        review.get_text()\n",
    "        text_list.append(review)\n",
    "    return text_list\n",
    "\n",
    "# Need to figure out the best ways to get all the reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy(page_source):\n",
    "    # Getting elements off page\n",
    "    toy_dict = {}\n",
    "    \n",
    "    # toy title\n",
    "    toy_title = scrape_toy_title(page_source)\n",
    "    toy_dict['title'] = toy_title\n",
    "\n",
    "    # toy price \n",
    "    toy_price = scrape_toy_price(page_source)\n",
    "    toy_dict['price'] = toy_price\n",
    "    \n",
    "    # toy description \n",
    "    toy_description = scrape_toy_description(page_source)\n",
    "    toy_dict['descriptions'] = toy_description\n",
    "    \n",
    "    try:\n",
    "        # toy key benefits \n",
    "        toy_keybenefits = scrape_toy_keybenefits(page_source)\n",
    "        toy_dict['key_benefits'] = toy_keybenefits\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # toy rating -- NEEDS FIXING\n",
    "    toy_rating = scrape_toy_rating(page_source)\n",
    "    toy_dict['rating'] = toy_rating\n",
    "\n",
    "    # toy reviews\n",
    "    toy_reviews = scrape_toy_reviews(page_source)\n",
    "    toy_dict['reviews'] = toy_reviews\n",
    "    return toy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_toy_page(toy_cat_dict, toy_subcat, toy_links): #products\n",
    "#     # Lopping through all products and scraping\n",
    "#     toys_links =[]\n",
    "#     for product in products:\n",
    "#         link = product.get_attribute('href')\n",
    "#         toys_links.append(link)\n",
    "\n",
    "    toy_subcat_dict = {}\n",
    "    for link in toy_links:\n",
    "        driver.get(link)\n",
    "        page_source = driver.page_source\n",
    "        toy_dict = scrape_toy(page_source)\n",
    "        toy_subcat_dict[link] = toy_dict\n",
    "\n",
    "    toy_cat_dict[toy_subcat] = toy_subcat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_toys(page_source):\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    numbers = soup.find_all('span', class_='category-count')\n",
    "#     print(numbers[0].text)\n",
    "    subcat_numbers = []\n",
    "    for span in numbers:\n",
    "        number = span.text\n",
    "        subcat_numbers.append(int(number[1:-1]))\n",
    "    return subcat_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_subcat_links(link, number_of_toys):\n",
    "    # https://www.chewy.com/b/moderate-2718\n",
    "    # https://www.chewy.com/b/moderate_c2718_p5\n",
    "    \n",
    "    main_href = f'{link[:-5]}_c{link[-4:]}_p'    \n",
    "    subcat_pages = []\n",
    "    subcat_pages.append(link)\n",
    "    for i in range(2, round(number_of_toys / 36)+1):\n",
    "        href = f'{main_href}{i}'\n",
    "        subcat_pages.append(href)\n",
    "    return subcat_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(page_source):\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    subcats = soup.find_all('a', class_='facet_selection')\n",
    "    links_list = []\n",
    "    for subcat in subcats:\n",
    "        link = subcat['href']\n",
    "        full_link = f'https://www.chewy.com{link}'\n",
    "        links_list.append(full_link)\n",
    "    return links_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_toy_links(subcat_pages):\n",
    "    toys_links =[]\n",
    "    for page in subcat_pages:\n",
    "        driver.get(page)\n",
    "        products = driver.find_elements_by_class_name('product')\n",
    "        # Lopping through all products on first page \n",
    "        for product in products:\n",
    "            link = product.get_attribute('href')\n",
    "            toys_links.append(link)\n",
    "    return toys_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d60e6171cc2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDRIVER_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moriginal_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.chewy.com/b/toys-315\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# To first just look at CHEW TOYS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             return self.request_encode_body(\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsi/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CHEW TOYS \n",
    "\n",
    "\n",
    "DRIVER_PATH = '/Users/haleytaft/Downloads/chromedriver'\n",
    "driver = webdriver.Chrome( executable_path=DRIVER_PATH) \n",
    "original_link = \"https://www.chewy.com/b/toys-315\"\n",
    "driver.get(original_link)\n",
    "\n",
    "# To first just look at CHEW TOYS\n",
    "chew_toys_link = driver.find_element_by_link_text('Chew Toys')\n",
    "chew_toys_link.click()\n",
    "\n",
    "# Defining a larger dictionary to hold subcat dictionaries\n",
    "chew_toys = {}\n",
    "\n",
    "# Going to MODERATE chew toys\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Moderate\")))\n",
    "element.click()\n",
    "\n",
    "# Checking for number of toys in each subcategory (looking at side bar)\n",
    "cat_page_source = driver.page_source\n",
    "chew_numbers = number_of_toys(cat_page_source)\n",
    "\n",
    "# Getting all first page links for each subcategory\n",
    "chew_links = get_links(cat_page_source)\n",
    "print(chew_links)\n",
    "\n",
    "# Getting links for all pages for moderate toys \n",
    "mod_pages_links = grab_subcat_links(chew_links[0], chew_numbers[0])\n",
    "all_moderate_links = grab_toy_links(mod_pages_links)\n",
    "\n",
    "# Collecting all MODERATE chew toys \n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Chew Toys\")))\n",
    "scrape_toy_page(chew_toys, 'moderate', all_moderate_links)\n",
    "\n",
    "# Back to Chew Toys\n",
    "driver.get('https://www.chewy.com/b/chew-toys-316')\n",
    "\n",
    "print('Done with Moderate Toys')\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# To get to TOUGH chew toys\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Tough\")))\n",
    "element.click()\n",
    "\n",
    "# Getting links for all pages for tough toys \n",
    "tough_pages_links = grab_subcat_links(chew_links[1], chew_numbers[1])\n",
    "print(tough_pages_links)\n",
    "all_tough_links = grab_toy_links(tough_pages_links)\n",
    "\n",
    "# Collecting all TOUGH chew toys \n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Chew Toys\")))\n",
    "scrape_toy_page(chew_toys, 'tough', all_tough_links)\n",
    "\n",
    "#To get back to Chew Toys\n",
    "driver.get('https://www.chewy.com/b/chew-toys-316')\n",
    "\n",
    "print(\"Done with Tough Toys\")\n",
    "\n",
    "################################################################################################\n",
    "# To get to EXTREME chew toys\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Extreme\")))\n",
    "element.click()\n",
    "\n",
    "# Getting links for all pages for extreme toys \n",
    "extreme_pages_links = grab_subcat_links(chew_links[2], chew_numbers[2])\n",
    "all_extreme_links = grab_toy_links(extreme_pages_links)\n",
    "\n",
    "# To look at the extreme chew toys \n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Chew Toys\")))\n",
    "scrape_toy_page(chew_toys, 'extreme', all_extreme_links)\n",
    "\n",
    "print('Done with Extreme Toys and Chew Toys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "chew_toy_list = []\n",
    "for subcat in ['moderate', 'tough', 'extreme']:\n",
    "    for index, link in enumerate(chew_toys[subcat]):\n",
    "        chew_toys[subcat][link]['subcat'] = subcat\n",
    "        chew_toys[subcat][link]['cat'] = 'chew toys'\n",
    "        chew_toy_list.append(chew_toys[subcat][link])\n",
    "chew_toy_df = pd.DataFrame(chew_toy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert chew toy data frame to csv -- uncomment to rerun \n",
    "# chew_toy_df.to_csv('./data/chewtoy_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plush_toys = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.chewy.com/b/stuffed-toys-2333', 'https://www.chewy.com/b/unstuffed-toys-2334']\n",
      "38\n",
      "1368\n",
      "Done with 11th round\n",
      "Done with 12th round\n",
      "Done with 13th round\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-2379d01f8286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done with 13th round'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mplush_toys_14\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mscrape_toy_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplush_toys_14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stuffed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_stuffed_links\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1301\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1403\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done with 14th round'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8ec44ecf0bb4>\u001b[0m in \u001b[0;36mscrape_toy_page\u001b[0;34m(toy_cat_dict, toy_subcat, toy_links)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpage_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtoy_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_toy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtoy_subcat_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3df37dfea325>\u001b[0m in \u001b[0;36mscrape_toy\u001b[0;34m(page_source)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# toy price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtoy_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_toy_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtoy_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoy_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-916e62e28f65>\u001b[0m in \u001b[0;36mscrape_toy_price\u001b[0;34m(page_source)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     price = soup.find('div', id='pricing').find(\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m'ul'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'product-pricing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m'li'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'our-price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "# PlUSH TOYS\n",
    "\n",
    "DRIVER_PATH = '/Users/haleytaft/Downloads/chromedriver'\n",
    "driver = webdriver.Chrome( executable_path=DRIVER_PATH) \n",
    "driver.get(\"https://www.chewy.com/b/toys-315\")\n",
    "\n",
    "# To first just look at CHEW TOYS\n",
    "chew_toys_link = driver.find_element_by_link_text('Plush Toys')\n",
    "chew_toys_link.click()\n",
    "\n",
    "# plush_toys = {}\n",
    "\n",
    "# Looking a the Stuffed toys\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Stuffed Toys\")))\n",
    "element.click()\n",
    "\n",
    "# Checking for number of toys in each subcategory (looking at side bar)\n",
    "cat_page_source = driver.page_source\n",
    "plush_numbers = number_of_toys(cat_page_source)\n",
    "\n",
    "# Getting all first page links for each subcategory\n",
    "plush_links = get_links(cat_page_source)\n",
    "print(plush_links)\n",
    "\n",
    "# Getting links for all pages for stuffed toys \n",
    "stuffed_pages_links = grab_subcat_links(plush_links[0], plush_numbers[0])\n",
    "print(len(stuffed_pages_links))\n",
    "all_stuffed_links = grab_toy_links(stuffed_pages_links)\n",
    "print(len(all_stuffed_links))\n",
    "\n",
    "# To look at the STUFFED plush toys \n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Plush Toys\")))\n",
    "\n",
    "# # Scraping\n",
    "# plush_toys_1 = {}\n",
    "# scrape_toy_page(plush_toys_1, 'stuffed', all_stuffed_links[:100])\n",
    "# print('Done with 1st round')\n",
    "# plush_toys_2 = {}\n",
    "# scrape_toy_page(plush_toys_2, 'stuffed', all_stuffed_links[101:200])\n",
    "# print('Done with 2nd round')\n",
    "# plush_toys_3 = {}\n",
    "# scrape_toy_page(plush_toys_3, 'stuffed', all_stuffed_links[201:300])\n",
    "# print('Done with 3rd round')\n",
    "# plush_toys_4 = {}\n",
    "# scrape_toy_page(plush_toys_4, 'stuffed', all_stuffed_links[301:400])\n",
    "# print('Done with 4th round')\n",
    "# plush_toys_5 = {}\n",
    "# scrape_toy_page(plush_toys_5, 'stuffed', all_stuffed_links[401:500])\n",
    "# print('Done with 5th round')\n",
    "# plush_toys_6 = {}\n",
    "# scrape_toy_page(plush_toys_6, 'stuffed', all_stuffed_links[501:600])\n",
    "# print('Done with 6th round')\n",
    "# plush_toys_7 = {}\n",
    "# scrape_toy_page(plush_toys_7, 'stuffed', all_stuffed_links[601:700])\n",
    "# print('Done with 7th round')\n",
    "# plush_toys_8 = {}\n",
    "# scrape_toy_page(plush_toys_8, 'stuffed', all_stuffed_links[701:800])\n",
    "# print('Done with 8th round')\n",
    "# plush_toys_9 = {}\n",
    "# scrape_toy_page(plush_toys_9, 'stuffed', all_stuffed_links[801:900])\n",
    "# print('Done with 9th round')\n",
    "# plush_toys_10 = {}\n",
    "# scrape_toy_page(plush_toys_10, 'stuffed', all_stuffed_links[901:1000])\n",
    "# print('Done with 10th round')\n",
    "# plush_toys_11 = {}\n",
    "# scrape_toy_page(plush_toys_11, 'stuffed', all_stuffed_links[1001:1100])\n",
    "# print('Done with 11th round')\n",
    "# plush_toys_12 = {}\n",
    "# scrape_toy_page(plush_toys_12, 'stuffed', all_stuffed_links[1101:1200])\n",
    "# print('Done with 12th round')\n",
    "# plush_toys_13 = {}\n",
    "# scrape_toy_page(plush_toys_13, 'stuffed', all_stuffed_links[1201:1300])\n",
    "# print('Done with 13th round')\n",
    "plush_toys_14 = {}\n",
    "scrape_toy_page(plush_toys_14, 'stuffed', all_stuffed_links[1301:1403])\n",
    "print('Done with 14th round')\n",
    "    \n",
    "#To get back to Chew Toys\n",
    "driver.get('https://www.chewy.com/b/plush-toys-320')\n",
    "\n",
    "print(\"Done with Stuffed subcategory!\")\n",
    "\n",
    "# ##########################################################################################################\n",
    "\n",
    "# # Looking a the Unstuffed toys\n",
    "# element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Unstuffed Toys\")))\n",
    "# element.click()\n",
    "\n",
    "# # Getting links for all pages for unstuffed toys \n",
    "# unstuffed_pages_links = grab_subcat_links(plush_links[1], plush_numbers[1])\n",
    "# print(unstuffed_pages_links)\n",
    "# all_unstuffed_links = grab_toy_links(unstuffed_pages_links)\n",
    "# print(len(all_unstuffed_links))\n",
    "\n",
    "# # To look at the unstuffed plush toys \n",
    "# check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Plush Toys\")))\n",
    "\n",
    "# # Scraping \n",
    "# plush_toys_15 = {}\n",
    "# scrape_toy_page(plush_toys_15, 'unstuffed', all_unstuffed_links[:50])\n",
    "# print(\"Done with 1st unstuffed toys\")\n",
    "# plush_toys_16 = {}\n",
    "# scrape_toy_page(plush_toys_16, 'unstuffed', all_unstuffed_links[51:100])\n",
    "# print(\"Done with 2nd unstuffed toys\")\n",
    "# plush_toys_16 = {}\n",
    "# scrape_toy_page(plush_toys_16, 'unstuffed', all_unstuffed_links[101:173])\n",
    "# print(\"Done with 3rd unstuffed toys\")\n",
    "\n",
    "# print(\"Done with Unstuffed subcategory!\")\n",
    "\n",
    "# print('Done with Plush category!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plush_toys['stuffed'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "plushlist = [plush_toys_1, plush_toys_2, plush_toys_3, plush_toys_4, plush_toys_5, plush_toys_6,\n",
    "            plush_toys_7, plush_toys_8, plush_toys_9, plush_toys_10, plush_toys_11,\n",
    "            plush_toys_12, plush_toys_13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for toydict in plushlist:\n",
    "    for item, link in enumerate(toydict['stuffed']):\n",
    "        plush_toys['stuffed'][link] = toydict['stuffed'][link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1273"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plush_toys['stuffed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "plush_toy_list = []\n",
    "for subcat in ['stuffed']: #, 'unstuffed'\n",
    "    for index, link in enumerate(plush_toys[subcat]):\n",
    "        plush_toys[subcat][link]['subcat'] = subcat\n",
    "        plush_toys[subcat][link]['cat'] = 'plush toys'\n",
    "        plush_toy_list.append(plush_toys[subcat][link])\n",
    "plush_toy_df = pd.DataFrame(plush_toy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "plush_toy_df.to_csv('./data/plushtoy_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# ROPE & TUG TOYS\n",
    "\n",
    "DRIVER_PATH = '/Users/haleytaft/Downloads/chromedriver'\n",
    "driver = webdriver.Chrome( executable_path=DRIVER_PATH) \n",
    "driver.get(\"https://www.chewy.com/b/toys-315\")\n",
    "\n",
    "# Getting the total number of toys\n",
    "page_source = driver.page_source \n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "numbers = soup.find_all('span', class_='category-count')\n",
    "print(numbers[0])\n",
    "\n",
    "# getting all the links to the pages to scrape\n",
    "rope_toy_link = 'https://www.chewy.com/b/rope-tug-toys-321'\n",
    "main_href = f'{link[:-4]}_c{link[-3:]}_p'    \n",
    "pages = []\n",
    "pages.append(link)\n",
    "for i in range(2, round(numbers / 36)+1):\n",
    "    href = f'{main_href}{i}'\n",
    "    pages.append(href)\n",
    "print(pages)\n",
    "\n",
    "stuffed_pages_links = grab_subcat_links(plush_links[0], plush_numbers[0])\n",
    "print(len(stuffed_pages_links))\n",
    "all_stuffed_links = grab_toy_links(stuffed_pages_links)\n",
    "\n",
    "# To first just look at ROPE & TUG TOYS\n",
    "rope_toys_link = driver.find_element_by_link_text('Rope & Tug Toys')\n",
    "rope_toys_link.click()\n",
    "\n",
    "rope_tug_toys = {}\n",
    "\n",
    "# To look at the rope & tug toys \n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Toys\")))\n",
    "\n",
    "# Getting all the actual toy links\n",
    "\n",
    "\n",
    "scrape_toy_page(rope_tug_toys, 'rope_toy_tugs', rope_tug_links )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.chewy.com/b/treat-toys-dispensers-2336', 'https://www.chewy.com/b/treat-dispenser-refills-11139', 'https://www.chewy.com/b/puzzle-toys-games-2335']\n",
      "Done with Treat Toys & Dispensers subcategory\n",
      "Done with Treat Dispenser Refills subcategory!\n",
      "Done with Puzzle Toys & Games\n",
      "Done with Interactive Toys category!\n"
     ]
    }
   ],
   "source": [
    "# INTERACTIVE TOYS\n",
    "\n",
    "DRIVER_PATH = '/Users/haleytaft/Downloads/chromedriver'\n",
    "driver = webdriver.Chrome( executable_path=DRIVER_PATH) \n",
    "driver.get(\"https://www.chewy.com/b/toys-315\")\n",
    "\n",
    "# To first just look at CHEW TOYS\n",
    "chew_toys_link = driver.find_element_by_link_text('Interactive Toys')\n",
    "chew_toys_link.click()\n",
    "\n",
    "interactive_toys = {}\n",
    "\n",
    "# The interactive toys\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Treat Toys & Dispensers\")))\n",
    "element.click()\n",
    "\n",
    "# Checking for number of toys in each subcategory (looking at side bar)\n",
    "cat_page_source = driver.page_source\n",
    "interactive_numbers = number_of_toys(cat_page_source)\n",
    "\n",
    "# Getting all first page links for each subcategory\n",
    "interactive_links = get_links(cat_page_source)\n",
    "print(interactive_links)\n",
    "\n",
    "# Getting links for all pages for treat toys & dispensers\n",
    "dispenser_pages_links = grab_subcat_links(interactive_links[0], interactive_numbers[0])\n",
    "all_dispenser_links = grab_toy_links(dispenser_pages_links)\n",
    "\n",
    "# To look at the dog treat toys & dispenser interactive toys\n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Interactive Toys\")))\n",
    "\n",
    "# Scraping\n",
    "scrape_toy_page(interactive_toys, 'treat toys & dispensers', all_dispenser_links)\n",
    "\n",
    "driver.get('https://www.chewy.com/b/interactive-toys-319')\n",
    "\n",
    "print('Done with Treat Toys & Dispensers subcategory')\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Treat Dispenser Refills\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Treat Dispenser Refills\")))\n",
    "element.click()\n",
    "\n",
    "# Getting links for all pages for treat toys & refills\n",
    "refills_pages_links = grab_subcat_links(interactive_links[1], interactive_numbers[1])\n",
    "all_refills_links = grab_toy_links(refills_pages_links)\n",
    "\n",
    "# To look at the dog treat dispensers refills interactive toys\n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Interactive Toys\")))\n",
    "\n",
    "# Scraping\n",
    "scrape_toy_page(interactive_toys, 'treat dispenser refills', all_refills_links)\n",
    "\n",
    "driver.get('https://www.chewy.com/b/interactive-toys-319')\n",
    "\n",
    "print('Done with Treat Dispenser Refills subcategory!')\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Puzzle toys and Games \n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Puzzle Toys & Games\")))\n",
    "element.click()\n",
    "\n",
    "# Getting links for all pages for puzzle toys & games\n",
    "game_pages_links = grab_subcat_links(interactive_links[2], interactive_numbers[2])\n",
    "all_game_links = grab_toy_links(game_pages_links)\n",
    "\n",
    "# To look at the dog puzzle toys & games\n",
    "check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Interactive Toys\")))\n",
    "\n",
    "# Scraping\n",
    "scrape_toy_page(interactive_toys, 'puzzle toys & games', all_game_links)\n",
    "\n",
    "driver.get('https://www.chewy.com/b/interactive-toys-319')\n",
    "\n",
    "print('Done with Puzzle Toys & Games')\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "# # Automatic Ball Launchers\n",
    "# element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Automatic Ball Launchers\")))\n",
    "# element.click()\n",
    "\n",
    "# # Getting links for all pages for automatic ball launchers\n",
    "# auto_pages_links = grab_subcat_links(interactive_links[3], interactive_numbers[3])\n",
    "# all_auto_links = grab_toy_links(auto_pages_links)\n",
    "\n",
    "# # To look at the dog automatic ball launchers\n",
    "# check = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, \"Interactive Toys\")))\n",
    "\n",
    "# interactive_toys_2 = {}\n",
    "\n",
    "# # Scraping\n",
    "# scrape_toy_page(interactive_toys_2, 'automatic ball launchers', all_auto_links)\n",
    "\n",
    "# print(\"Done with Automatic Ball Launchers subcategory!\")\n",
    "\n",
    "print(\"Done with Interactive Toys category!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_toys_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_toy_list = []\n",
    "for subcat in ['treat toys & dispensers', 'treat dispenser refills', 'puzzle toys & games']: #, 'automatic ball launchers'\n",
    "    for index, link in enumerate(interactive_toys[subcat]):\n",
    "        interactive_toys[subcat][link]['subcat'] = subcat\n",
    "        interactive_toys[subcat][link]['cat'] = 'interactive toys'\n",
    "        interactive_toy_list.append(interactive_toys[subcat][link])\n",
    "interactive_toy_df = pd.DataFrame(interactive_toy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_df_list = []\n",
    "# for cat in interactive_toys:\n",
    "#     for toy in cat:\n",
    "#         interactive_df_list.append(toy)\n",
    "# interactive_df = pd.DataFrame(interactive_df_list)\n",
    "# interactive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive_toy_df.to_csv('./data/interactivetoy_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
